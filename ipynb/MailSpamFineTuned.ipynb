{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1949e77b-98b4-47f5-9c94-7a4244785a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline, BertForSequenceClassification, AutoTokenizer\n",
    "from datasets import Features, Value\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import notebook_login\n",
    "#git config --global credential.helper store\n",
    "#https://github.com/git-ecosystem/git-credential-manager/releases/tag/v2.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07157ff4-6b2d-4e80-8484-6e3bea98a152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7670a7d5a5884a7fb40d99e498929c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "980b0325-fe42-4e76-863c-8410992b2022",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25b56fb7-e3d9-4859-97ff-5c0038200c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "dataset=load_dataset(\"SetFit/enron_spam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5ba8c56-e24a-4f6e-b615-c872a3bb6328",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['ham', 'spam']\n",
    "id2label = {\n",
    "    0: \"ham\",\n",
    "    1: \"spam\"\n",
    "}\n",
    "label2id = {\n",
    "    \"ham\": 0,\n",
    "    \"spam\": 1\n",
    "}\n",
    "print (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c847bcc9-cff2-4ed6-bfcb-e6e081a4b600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['message_id', 'text', 'label', 'label_text', 'subject', 'message', 'date'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']=dataset['train'].shuffle().select(range(5000))\n",
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cae7848f-a72b-4273-a5f9-05b876e029cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['message_id', 'text', 'label', 'label_text', 'subject', 'message', 'date'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test']=dataset['test'].shuffle().select(range(500))\n",
    "dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c498a81-fa68-47fd-a7d0-73c304ac470f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['message_id', 'text', 'label', 'label_text', 'subject', 'message', 'date'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['message_id', 'text', 'label', 'label_text', 'subject', 'message', 'date'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d75dc77-8f06-4144-b3be-f0c00d71444d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad2f015c6414515b7521c2f30a3de02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559bf378b28a4f23a640e6be925d8f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[0, 1] - Spam\n",
    "#[1, 0] - Ham\n",
    "def preprocess_data(examples):\n",
    "    text = examples[\"text\"]\n",
    "    encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128)\n",
    "    encoding[\"labels\"] = [[0.0, 1.0] if label==1 else [1.0, 0.0] for label in examples['label']]\n",
    "    return encoding\n",
    "\n",
    "encoded_dataset=dataset.map(preprocess_data, remove_columns=dataset['train'].column_names, batched=True)\n",
    "encoded_dataset #TODO: Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afbce713-a298-4e59-9ae0-d7de6b4fa1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (encoded_dataset['train']['labels'][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "014f801d-e662-42a5-ab75-741eb2b7c04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] joint venture some emerging documents ( early days ) but good for information purposes - - - - - - - - - - - - - - - - - - - - - - forwarded by mike jordan / lon / ect on 06 / 04 / 2001 14 : 42 - - - - - - - - - - - - - - - - - - - - - - - - - - - coralie evans 05 / 04 / 2001 08 : 52 to : mike jordan / lon / ect @ ect cc : subject : joint venture please find attached the draft soap ( pretty rough ) and the business [SEP]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = encoded_dataset['train'][0]\n",
    "print(example.keys())\n",
    "tokenizer.decode(example['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82a986dc-1f2a-4bfc-ad87-af50839bc2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba35151c-7f2b-4709-8afa-8da456815474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", \n",
    "                                                           problem_type=\"multi_label_classification\", \n",
    "                                                           num_labels=len(labels),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id\n",
    "                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5bc2e9d-dcdd-4f12-9c49-c8e2742a87cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "metric_name = \"f1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "238bbc0d-43b5-4bde-9b55-30a80555ebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=f\"bert-mail-spam-finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a282f5e-b985-4a3e-a171-e8703f346c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "args = TrainingArguments(\n",
    "    model_path,\n",
    "    eval_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    #label_names=labels,\n",
    "    #push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82a9dd18-3d7f-400a-85ae-1df7a06a355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "    \n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8124c76d-9f22-4064-9ff6-d1c0d794364e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['train'][0]['labels'].type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96e3044d-c8bd-4376-b0fe-b4e429bc913c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  4101,  6957,  2070,  8361,  5491,  1006,  2220,  2420,  1007,\n",
       "         2021,  2204,  2005,  2592,  5682,  1011,  1011,  1011,  1011,  1011,\n",
       "         1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,\n",
       "         1011,  1011,  1011,  1011,  1011,  1011,  1011,  2830,  2098,  2011,\n",
       "         3505,  5207,  1013,  8840,  2078,  1013, 14925,  2102,  2006,  5757,\n",
       "         1013,  5840,  1013,  2541,  2403,  1024,  4413,  1011,  1011,  1011,\n",
       "         1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,\n",
       "         1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,  1011,\n",
       "         1011,  1011,  1011,  1011, 11034,  2666,  6473,  5709,  1013,  5840,\n",
       "         1013,  2541,  5511,  1024,  4720,  2000,  1024,  3505,  5207,  1013,\n",
       "         8840,  2078,  1013, 14925,  2102,  1030, 14925,  2102, 10507,  1024,\n",
       "         3395,  1024,  4101,  6957,  3531,  2424,  4987,  1996,  4433,  7815,\n",
       "         1006,  3492,  5931,  1007,  1998,  1996,  2449,   102])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['train']['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0221a01a-11fa-47b8-abfd-b89907cb7e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.6370, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), logits=tensor([[ 0.1364, -0.0950]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forward pass\n",
    "outputs = model(\n",
    "    input_ids=encoded_dataset['train']['input_ids'][0].unsqueeze(0), \n",
    "    labels=encoded_dataset['train'][0]['labels'].unsqueeze(0)\n",
    ")\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25ab35eb-e98c-4016-8881-56b73aabfb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "896cbacb-a820-4d0c-81a5-90bb6d36f994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='835' max='835' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [835/835 08:24, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.055938</td>\n",
       "      <td>0.982036</td>\n",
       "      <td>0.982000</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.034712</td>\n",
       "      <td>0.994000</td>\n",
       "      <td>0.994000</td>\n",
       "      <td>0.994000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.044948</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>0.988000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.054111</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>0.988000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.057024</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>0.988000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=835, training_loss=0.0515995609546136, metrics={'train_runtime': 506.301, 'train_samples_per_second': 49.378, 'train_steps_per_second': 1.649, 'total_flos': 1644444096000000.0, 'train_loss': 0.0515995609546136, 'epoch': 5.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "294663a6-5477-4886-8a5a-205033c34b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.03471248224377632,\n",
       " 'eval_f1': 0.994,\n",
       " 'eval_roc_auc': 0.994,\n",
       " 'eval_accuracy': 0.994,\n",
       " 'eval_runtime': 3.2806,\n",
       " 'eval_samples_per_second': 152.41,\n",
       " 'eval_steps_per_second': 5.182,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70e72d6c-2119-4834-8c22-3a5be9efacc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85d86ae7-5220-4987-a1cf-e878e61d4c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7532a4feb157429d97e371134376c205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2d74db5d524f579b45ba029dc5d8a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee8c47e116340b9859cf2ce33e3764e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/alexsd06/bert-mail-spam-finetuned/commit/e6f0874e45551c741e183cee042e89dbfc334cb7', commit_message='End of training', commit_description='', oid='e6f0874e45551c741e183cee042e89dbfc334cb7', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "926a6797-b9ee-4210-bc49-ff3f9cc7bacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline('text-classification', model=model_path, device='cuda', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c1b29a5-c1be-4762-b680-889f553ff14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'ham', 'score': 0.9937520623207092}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message=\"\"\"\n",
    "The interview is in 2 days! Best regards, David!\n",
    "\"\"\"\n",
    "pipe(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1bd35b5-73b7-4beb-a4b8-c0f03da9364d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 500/500 [00:07<00:00, 69.29it/s]\n"
     ]
    }
   ],
   "source": [
    "idx='test'\n",
    "l=len(dataset[idx])\n",
    "good, bad = 0, 0\n",
    "shown=0\n",
    "for item in tqdm(dataset[idx]):\n",
    "    text=item['text']\n",
    "    label=item['label']\n",
    "    label=id2label[label]\n",
    "    predict=pipe(text)[0]['label']\n",
    "    #if predict=='spam':\n",
    "    #    print ('spam') #The model nevers predicts spam!!!\n",
    "    #    break\n",
    "    if predict==label:\n",
    "        good+=1\n",
    "    else:\n",
    "        bad+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9ab93e2-1f8d-4d9b-91f9-8024d83ca618",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f'Accuracy {100*good/l}%!')\n",
    "print (f'Loss {100*bad/l}%!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb70a78-72f5-44c7-aae3-a6129943a219",
   "metadata": {},
   "source": [
    "**Raport:**\n",
    "1. Training data: Accuracy 99.56%! Loss 0.44%!\n",
    "2. Test data: Accuracy 99.4%! Loss 0.6%!\n",
    "\n",
    "**Note:** This was done on a small sample of the dataset: 5000 training, 500 testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99cf0a1-142e-4bd8-9bb4-6ef015f98fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
